{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c8c806-fcab-420e-8169-ed342d3a8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a539e0b-cddc-4023-a079-4a6df99ccb4d",
   "metadata": {},
   "source": [
    "#### Extracting data from the Quotebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4cd23-8496-4aa7-8ec5-26cc0d90944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re , math\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import sparse\n",
    "nltk.download('punkt')\n",
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bfe567-088f-4c48-afe3-9dd978bc5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to Quotebank file\n",
    "path_to_file = 'data/Quotebank/quotes-2018.json.bz2'\n",
    "\n",
    "#list with keywords for global warming\n",
    "keywords_gw=['climatechange', 'global warming', 'fossil fuels', 'carbon dioxide', 'methane', 'co2', 'carbon neutral', 'sustainable', 'greenhouse gases', 'emission', 'sea-level rise', 'temperature', 'renewable energy', 'carbon footprint', 'deforestation', 'atmospheric aerosols', 'biofuel', 'cap and trade', 'Clean coal technology', 'Greenhouse effect', 'IPCC ', 'Kyoto Protocol', 'Major Economies Forum on Energy and Climate', 'Ocean acidification ', 'polution', 'UNFCCC ']\n",
    "#list of keywords for abotion\n",
    "keywords_ab = ['abortion', 'abortifacient', 'abortion on demand', 'abortion on request', 'age of consent', 'age of consent', 'Back-street abortion', 'Carrying a pregnancy to term', 'Conscientious objection', 'Fertilisation', 'Fetus', 'Gestation', 'Implantation', 'Induced abortion', 'Miscarriage', 'Pregnancy', 'Termination of pregnancy', 'abortion pill', 'abstinence', 'pro-life', 'pro-choice', 'anti-choice', 'borth control', 'Comstock Act', 'conception', 'contraception', 'contraceptive', 'Doe v. Bolton', 'embryo', 'Hyde Amendment', 'Intrauterine device', 'IUD', 'Planned Parenthood', 'medical abprtion', 'morning-after pill', 'misoprostol', 'Roe v. Wade', 'vacum aspiration abprtion', 'reproductive rights']\n",
    "#list of keywords for gun rights\n",
    "keywords_gun = ['gun rights', 'gun control', 'firearm owners protection act', 'title II', 'national firearm act', 'assault weapons ban', 'second amendment', 'national riffle association', 'march for our lives', 'gunowners of america', 'assault weapon', 'automatic weapon', 'semiautomatic weapon', 'Brady law', 'national instant criminal background check system', 'gun show loophole', 'strawman purchase', 'mass shootings', 'open carry', 'nonproliferation', 'gun law', 'the right of self-defence', 'gun crime', 'ban assault rifles', 'gun regulations', 'gun lobby', 'Washington DC vs Heller', 'Sandy Hook promise', 'gun license', 'gun ownership' ]\n",
    "#list of keywords for gender ineqaulity\n",
    "keywords_gen = ['gender inequality', 'gender discrimination', 'gender bias', 'gender blindness', 'gender equity', 'gender pay gap', 'unconscious biases', 'occupational segregation', 'wikigender', 'substantive equality', 'structural discrimination', 'structural barriers', 'patriarchy', 'parity education', 'gender stereotyping', 'gender-sensitive policies', 'gender roles', 'gender norms', 'gender mainstreaming', 'gender gap', 'gender equity', 'women empowerment', 'sexism', 'misogyny', 'feminism', 'misandry', 'title IX', 'male gaze', 'bropropriating', 'mansplain', 'manterrupting', 'toxic masculinity', 'male privilege']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fd3be-f559-460b-a172-9b3cd82bdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk,keywords):\n",
    "    #logging\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    #reurn only rows containing key words\n",
    "    return chunk[chunk['quotation'].apply(lambda x:any(key in ' '.join([wnl.lemmatize(words) for words in nltk.word_tokenize(re.sub('[^A-Za-z0-9\\s]+', '', x.lower()))]) for key in keywords))]\n",
    "\n",
    "def extract(keywords)\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    #lemmatization\n",
    "    keywords_lm=[' '.join(words) for words in [nltk.word_tokenize(key) for key in keywords]]\n",
    "    \n",
    "    #reading big file by chunks\n",
    "    df_reader =pd.read_json(path_to_file, lines=True, compression='bz2', chunksize=500000)\n",
    "    k=0\n",
    "    for chunk in df_reader:\n",
    "        gl_warm=process_chunk(chunk,keywords_lm).copy()\n",
    "        gl_warm.to_csv('global_warming_2018'+'_'+str(k)+'.csv')\n",
    "        k+=1\n",
    "\n",
    "extract(keywords_gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44ca5f-a0e2-4302-9af3-5cc5ef5ff159",
   "metadata": {},
   "source": [
    "Concatenating files after extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983648f7-20f2-4701-a2e4-6fee27a3147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(dir_in,file_out):\n",
    "    df=pd.DataFrame()\n",
    "    for file in os.listdir(dir_in):\n",
    "        if file[-3:]=='csv':\n",
    "            df_cur=pd.read_csv(dir_in+'/'+file,index_col='Unnamed: 0')\n",
    "            df=pd.concat([df,df_cur]).copy()\n",
    "    df.to_csv(file_out)\n",
    "concat('out/2017','data/global_warming/global_warming_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afcaa23-5d2d-43c1-bd03-9784e7c938ac",
   "metadata": {},
   "source": [
    "#### Merging and cleaning all the years into one file with speakers' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb1a307-d48e-430a-a8ea-930382661aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(path):\n",
    "    d=pd.read_csv(path,index_col='Unnamed: 0')\n",
    "    d['probas']=d['probas'].apply(lambda x: re.sub('[\\[\\]\\'\\s]','',x).split(','))\n",
    "    d['pr']=d['probas'].apply(lambda x: [x[i] for i in range(len(x)) if i%2==1])\n",
    "    d['au_pr']=d['probas'].apply(lambda x: [x[i] for i in range(len(x)) if i%2==0])\n",
    "    d=d[d['pr'].apply(lambda x: all([len(x[i])>1  for i in range(len(x))]))].copy() #deleting empty probas\n",
    "    d=d[d['pr'].apply(lambda x: all([x[i][0]=='0' for i in range(len(x))]))].copy() #deleting wrong parsed probas\n",
    "    d=d[d['pr'].apply(lambda x: float(x[0])-float(x[1])>0.3)] #deleting uncertained authors\n",
    "    d=d[d['speaker']!='None'].copy() #deleting None author\n",
    "    df_out=d[['quotation','speaker','qids','numOccurrences','urls']] #leaving only usefull columns\n",
    "    print('Size of the cleaned dataframe is',df_out.shape)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cec8df7-b125-452c-8833-f66a4f538df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_attributes(df_out):\n",
    "    #merging with information about speakers\n",
    "    dff=pd.DataFrame()\n",
    "    for i in range(0,16):\n",
    "        if i<10:\n",
    "            s='0'+str(i)\n",
    "        else:\n",
    "            s=str(i)\n",
    "        df=pd.read_parquet('data/speaker_attributes/part-000'+s+'-0d587965-3d8f-41ce-9771-5b8c9024dce9-c000.snappy.parquet')\n",
    "        df['year_of_birth']=df['date_of_birth'].apply(lambda x: x[0].split('-')[0].strip('+') if x is not None else x)\n",
    "        dff=pd.concat([dff,df_out.merge(df[['gender', 'nationality', 'ethnic_group', 'academic_degree', 'religion','label','year_of_birth']],how='left',left_on='speaker',right_on='label').dropna(subset=['gender'])]).copy()\n",
    "    #getting final dataframe\n",
    "    dff=dff.drop_duplicates(subset=['speaker','quotation']).copy()\n",
    "    dff=dff.drop(columns='label').copy()\n",
    "    print('Size of the dataframe with information about authors is',dff.shape)\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d53ab6-b93b-499c-a245-920e4952b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df(dir):\n",
    "    final=pd.DataFrame()\n",
    "    for file in os.listdir(dir):\n",
    "        if file[-3:]=='csv':\n",
    "            df_out=clean_df(os.path.join(dir,file))\n",
    "            dff=merge_attributes(df_out)\n",
    "            dff['year']=file.split('_')[-1].split('.')[0]\n",
    "            final=pd.concat([final,dff]).copy()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a94ef39-f32b-492a-af9a-6fe00954e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the cleaned dataframe is (23085, 5)\n",
      "Size of the dataframe with information about authors is (21426, 11)\n",
      "Size of the cleaned dataframe is (11613, 5)\n",
      "Size of the dataframe with information about authors is (10858, 11)\n",
      "Size of the cleaned dataframe is (14562, 5)\n",
      "Size of the dataframe with information about authors is (13531, 11)\n",
      "Size of the cleaned dataframe is (16652, 5)\n",
      "Size of the dataframe with information about authors is (15439, 11)\n",
      "Size of the cleaned dataframe is (21494, 5)\n",
      "Size of the dataframe with information about authors is (19880, 11)\n",
      "Size of the cleaned dataframe is (13089, 5)\n",
      "Size of the dataframe with information about authors is (12167, 11)\n"
     ]
    }
   ],
   "source": [
    "final_df('data/global_warming').to_csv('data/attributes/global_warming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a548796a-e33a-4b4b-987e-30c6a0d5f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the cleaned dataframe is (8611, 5)\n",
      "Size of the dataframe with information about authors is (8085, 11)\n",
      "Size of the cleaned dataframe is (1636, 5)\n",
      "Size of the dataframe with information about authors is (1510, 11)\n",
      "Size of the cleaned dataframe is (1610, 5)\n",
      "Size of the dataframe with information about authors is (1442, 11)\n",
      "Size of the cleaned dataframe is (1070, 5)\n",
      "Size of the dataframe with information about authors is (1001, 11)\n",
      "Size of the cleaned dataframe is (1362, 5)\n",
      "Size of the dataframe with information about authors is (1263, 11)\n",
      "Size of the cleaned dataframe is (1940, 5)\n",
      "Size of the dataframe with information about authors is (1828, 11)\n"
     ]
    }
   ],
   "source": [
    "final_df('data/abortion').to_csv('data/attributes/abortion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad7b2b04-805d-42a6-a8c3-28fc5a759a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the cleaned dataframe is (1834, 5)\n",
      "Size of the dataframe with information about authors is (1679, 11)\n",
      "Size of the cleaned dataframe is (1639, 5)\n",
      "Size of the dataframe with information about authors is (1538, 11)\n",
      "Size of the cleaned dataframe is (1442, 5)\n",
      "Size of the dataframe with information about authors is (1336, 11)\n",
      "Size of the cleaned dataframe is (1919, 5)\n",
      "Size of the dataframe with information about authors is (1782, 11)\n",
      "Size of the cleaned dataframe is (1568, 5)\n",
      "Size of the dataframe with information about authors is (1444, 11)\n",
      "Size of the cleaned dataframe is (816, 5)\n",
      "Size of the dataframe with information about authors is (738, 11)\n"
     ]
    }
   ],
   "source": [
    "final_df('data/gun_control').to_csv('data/attributes/gun_control.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b7ffb6f-711e-4c4d-a45c-069ea8d9fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the cleaned dataframe is (1483, 5)\n",
      "Size of the dataframe with information about authors is (1410, 11)\n",
      "Size of the cleaned dataframe is (2445, 5)\n",
      "Size of the dataframe with information about authors is (2303, 11)\n",
      "Size of the cleaned dataframe is (3235, 5)\n",
      "Size of the dataframe with information about authors is (3064, 11)\n",
      "Size of the cleaned dataframe is (6079, 5)\n",
      "Size of the dataframe with information about authors is (5715, 11)\n",
      "Size of the cleaned dataframe is (1030, 5)\n",
      "Size of the dataframe with information about authors is (974, 11)\n",
      "Size of the cleaned dataframe is (833, 5)\n",
      "Size of the dataframe with information about authors is (782, 11)\n"
     ]
    }
   ],
   "source": [
    "final_df('data/gender_inequality').to_csv('data/attributes/gender_inequality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eda8e0-c082-494d-911b-02dc1d7c0a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
